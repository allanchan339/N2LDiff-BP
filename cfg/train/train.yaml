#### Test Settings
test_folder: 'data/LOL/eval15'
results_folder: './results_scratch'
diffusion_path:  ""
use_wandb: True

#debug
fast_dev_run: False  # use for debug if int or True are set, False for normal training
flash_attn_valid_switch: False

# ablation study
BPAttnOrBPFFN: True
BPAttn: True
BPFFN: True
lambda_num: 1

profiler: null # simple, advanced, null, pytorch
limit_train_batches: 1.0

# hardware setting
devices: [0, 1]
strategy: ddp 

# pytorch lightning
accumulate_grad_batches: 1  # Lion only perform well on large batch
benchmark: True
enable_checkpointing: True  # customed checkpointing is available
gradient_clip_val: 1.0  # must for 16 bit training
gradient_clip_algorithm: 'norm'  # 'norm' or 'value'
precision: 'bf16' # 'bf16' or 32
accelerator: 'auto'
max_epochs: 1000
min_epochs: 1
log_every_n_steps: 10
detect_anomaly: False 
deterministic: False
num_sanity_val_steps: 0
check_val_every_n_epoch: 1

# model
mul: 16 
paddingMode: False # if null, then center crop applied

in_dim: 6
unet_outdim: 3
dim_mults: !!python/tuple [1, 2, 2, 4, 4]
use_attn: False
use_ViT: True
unet_dim: 64
use_in: True
weight_init: True
stronger_cond: False 
use_wn: True

dim_adjust_factor: 1.5
num_blocks: [1,3,6,12] #[2,4,8,16]
heads: [2,4,8,16]
ffn_expansion_factor: 2.66
bias: True
LayerNorm_type: 'WithBias'
skip: False


# encoder
cond_in_dim: 12
cond_on_res: False

# Diffusion 
return_all_timesteps: False
clip_denoised: True  # clip when reverse process,
rescale_ratio: 1.0
timesteps: 100
on_res: False
use_center: True
use_center_sampler: True
on_cond: 'img_lr'  # img_c, img_lr or h(img_lr)
sample_mode: 'ddpm'
loss_type: 'combined'
lpips_type: 'vgg' #'alex', 'vgg', 'squeeze'

# training 
seed: 3407
train_lr: 0.0004   # Lion 0.0004
optimizer: 'Lion'  # AdamW or Lion (good at large batch)
weight_decay: !!float 1e-4

# scheduler
scheduler: null #good results start at epoch 40
warmup: 50
max_iters: 100
factor: 0.9
patience: 50
min_lr: 0.00005
optim_mode: 'max'

# dataset
image_size: 192
scale_factor: 1.0
pin_memory: True
num_workers: 32
color_space: 'rgb'
use_dataset: 'LOL+LOLv2+VELOL' # 'LOL+LOLv2'
persistent_workers: False
train_folders_v1: 'data/LOL/our485'
train_folders_v2: 'data/LOLv2/LOL-v2/Real_captured/Train'
train_folders_VE: 'data/VE-LOL-L/VE-LOL-L-Cap-Full/train'
train_batch_size: 16
batch_size: 16
switch_normal_low: True

